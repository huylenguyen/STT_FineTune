{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required module for text to speech synthesis\n",
    "from gtts import gTTS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "# Total vocabulary\n",
    "LETTERS = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"]\n",
    "\n",
    "PHONETIC_LETTERS = [\"Alfa\", \"Bravo\", \"Charlie\", \"Delta\", \"Echo\", \"Foxtrot\", \"Golf\", \"Hotel\", \"India\", \"Juliett\", \"Kilo\", \"Lima\", \"Mike\",\"November\",\n",
    "\"Oscar\", \"Papa\", \"Quebec\", \"Romeo\", \"Sierra\", \"Tango\", \"Uniform\", \"Victor\", \"Whiskey\", \"Xray\", \"Yankee\", \"Zulu\"]\n",
    "\n",
    "PHONETIC_NUMBERS =[\"Zero\", \"One\", \"Two\", \"Three\", \"Four\", \"Fife\", \"Six\", \"Seven\", \"Eight\", \"Niner\"]\n",
    "\n",
    "DESIGNATOR = [\"Ryanair\", \"Speedbird\", \"Astraeus\"]\n",
    "\n",
    "CALLSIGN = [\"RYA\", \"BAW\", \"AEU\"]\n",
    "\n",
    "ACTION_TYPE = [\"Flight Level\", \"Heading\", \"Speed\", \"Incomm\", \"Outcomm\", \"Route\"]\n",
    "\n",
    "ACTION_CLIMB = [\"climb\", \"descend\"]\n",
    "\n",
    "SUB_ACTION_HEADING = [\"Absolute\", \"Relative\", \"Continue\"]\n",
    "\n",
    "SUB_ACTION_SPEED = [\"Knots\", \"Mach\"]\n",
    "\n",
    "SUB_ACTION_ROUTE = [\"On Route\", \"Resume\"]\n",
    "\n",
    "NEIGHBOUR_SECTORS = [\"London\"]\n",
    "\n",
    "MISC_VOCAB = [\"hundred\", \"degrees\", \"left\", \"right\", \"roger\"]\n",
    "\n",
    "vocab = PHONETIC_LETTERS + PHONETIC_NUMBERS + DESIGNATOR + \\\n",
    "        ACTION_TYPE + ACTION_CLIMB + SUB_ACTION_HEADING + SUB_ACTION_SPEED + SUB_ACTION_ROUTE + \\\n",
    "        NEIGHBOUR_SECTORS + MISC_VOCAB\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "vocab = list(filter(lambda x: x not in [\"Incomm\", \"Outcomm\", \"On Route\", \"Absolute\", \"Relative\"], vocab))\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "ACCENT = [\"com.au\", \"co.uk\", \"com\", \"ca\", \"co.in\", \"ie\", \"co.za\"]\n",
    "df_fixes= pd.read_csv('data_sector/s25_waypoints.csv')\n",
    "s25_fixes = df_fixes[\"fix\"].values.tolist()\n",
    "\n",
    "# Aircraft identifier string length\n",
    "IDENTIFIER_LENGTH = 3\n",
    "\n",
    "# Flight levels\n",
    "MIN_FL = 10\n",
    "MAX_FL = 600\n",
    "FL = np.arange(MIN_FL, MAX_FL, 10) \n",
    "# Heading angles (absolute, relative)\n",
    "ANGLE_ABS = np.arange(5,360, 5)\n",
    "ANGLE_REL = np.arange(5,40, 5)\n",
    "# Speed \n",
    "SPEED_MACH = np.arange(30, 90, 5 )\n",
    "SPEED_KNTS = np.arange(150, 300, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions \n",
    "\n",
    "def gen_call_sign():\n",
    "    # Output string\n",
    "    output_spoken = \"\"\n",
    "    output_str = \"\"\n",
    "\n",
    "    # Pick a random airline\n",
    "    idx = np.random.randint(0, len(DESIGNATOR))\n",
    "    output_spoken +=  DESIGNATOR[idx] + \" \"\n",
    "    output_str += CALLSIGN[idx]\n",
    "\n",
    "    # Pick random numerics of length IDENTIFIER_LENGTH\n",
    "    for i in range(IDENTIFIER_LENGTH):\n",
    "        # Letter or number\n",
    "        if random.random() < 0.5: # Letter\n",
    "            idx = np.random.randint(0, len(PHONETIC_LETTERS))\n",
    "            output_spoken += PHONETIC_LETTERS[idx] + \" \"\n",
    "            output_str += LETTERS[idx]\n",
    "        else: # Number\n",
    "            idx = np.random.randint(0, len(PHONETIC_NUMBERS))\n",
    "            output_spoken += PHONETIC_NUMBERS[idx] + \" \"\n",
    "            output_str += str(idx)\n",
    "    \n",
    "    output_spoken = output_spoken[:-1]\n",
    "\n",
    "    return output_spoken, output_str\n",
    "\n",
    "# Generate a random flight level within the bounds\n",
    "def gen_flight_level():\n",
    "    # Output string\n",
    "    output_spoken = \" \" + ACTION_TYPE[0]\n",
    "    output_str = \"_FL_\"\n",
    "\n",
    "    # Add optional action phrase\n",
    "    if random.random() < 0.5:\n",
    "        output_spoken = \" \" + random.choice(ACTION_CLIMB) + output_spoken\n",
    "    \n",
    "    # Pick a random flight level\n",
    "    fl = random.choice(FL)\n",
    "    output_str += str(fl)\n",
    "\n",
    "    # Generate corresponding tokens\n",
    "    if fl % 100 == 0:\n",
    "        output_spoken += \" \" + PHONETIC_NUMBERS[int(fl / 100)] + \" hundred\"\n",
    "    else:\n",
    "        for k in str(fl):\n",
    "            output_spoken += \" \" + PHONETIC_NUMBERS[int(k)]\n",
    "    \n",
    "    return output_spoken, output_str\n",
    "\n",
    "# Generate a random heading within the bounds\n",
    "def gen_heading():\n",
    "    # Output string\n",
    "    output_spoken = \"\"\n",
    "    output_str = \"\"\n",
    "\n",
    "    # Draw a sub-action heading\n",
    "    subaction_type = random.choice(SUB_ACTION_HEADING)\n",
    "\n",
    "    # Handle each sub-action type\n",
    "    if subaction_type == \"Absolute\":\n",
    "        output_spoken += \" fly heading \"\n",
    "        output_str += \"_Abs_\"\n",
    "        \n",
    "        # Draw heading\n",
    "        heading_angle = str(random.choice(ANGLE_ABS))\n",
    "        heading_angle.rjust(3, \"0\")\n",
    "        \n",
    "        # Convert spoken string\n",
    "        for i in heading_angle:\n",
    "            output_spoken += PHONETIC_NUMBERS[int(i)] + \" \"\n",
    "        output_spoken += \"degrees\"\n",
    "        output_str += heading_angle\n",
    "    \n",
    "    elif subaction_type == \"Relative\":\n",
    "        # Draw heading\n",
    "        heading_angle = str(random.choice(ANGLE_REL))\n",
    "        direction = random.choice([\"left\", \"right\"])\n",
    "\n",
    "        output_spoken += \" turn \" + direction + \" \"\n",
    "        output_str += \"_Rel_\" + direction + \"_\" + heading_angle\n",
    "\n",
    "        # Convert spoken string\n",
    "        for i in heading_angle:\n",
    "            output_spoken += PHONETIC_NUMBERS[int(i)] + \" \"\n",
    "        output_spoken += \"degrees\"\n",
    "\n",
    "    elif subaction_type == \"Continue\":\n",
    "        output_spoken += \" continue present heading\"\n",
    "        output_str += \"_Cont\"\n",
    "\n",
    "    return output_spoken, output_str\n",
    "\n",
    "def gen_speed():\n",
    "    # Output string\n",
    "    output_spoken = \"\"\n",
    "    output_str = \"\"\n",
    "\n",
    "    # Draw a sub-action heading\n",
    "    subaction_type = random.choice(SUB_ACTION_SPEED)\n",
    "\n",
    "    # Handle each sub-action type\n",
    "    if subaction_type == \"Mach\":\n",
    "        output_spoken += \" Mach decimal \"\n",
    "        output_str += \"_Mach_\"\n",
    "\n",
    "        # Draw speed\n",
    "        speed = str(random.choice(SPEED_MACH))\n",
    "        \n",
    "        # Convert spoken string\n",
    "        for i in speed:\n",
    "            output_spoken += PHONETIC_NUMBERS[int(i)] + \" \"\n",
    "        output_str += speed\n",
    "\n",
    "    elif subaction_type == \"Knots\":\n",
    "        output_spoken += random.choice([\" speed \", \" fly speed \", \" make your speed \"])\n",
    "        output_str += \"_Knots_\"\n",
    "\n",
    "        # Draw speed\n",
    "        speed = str(random.choice(SPEED_KNTS))\n",
    "        \n",
    "        # Convert spoken string\n",
    "        for i in speed:\n",
    "            output_spoken += PHONETIC_NUMBERS[int(i)] + \" \"\n",
    "        output_spoken += \"knots \"\n",
    "        output_str += speed\n",
    "\n",
    "    output_spoken = output_spoken[:-1]\n",
    "\n",
    "    return output_spoken, output_str\n",
    "\n",
    "# Incoming communications\n",
    "def gen_incomms():\n",
    "    output_spoken = \" roger\"\n",
    "    output_str = \"_InComms\"\n",
    "    return output_spoken, output_str\n",
    "\n",
    "# Outgoing communications\n",
    "def gen_outcomms():\n",
    "    # Draw neighbour\n",
    "    neighbour = random.choice(NEIGHBOUR_SECTORS)\n",
    "    # Convert string\n",
    "    output_spoken = \" contact \" + neighbour\n",
    "    output_str = \"_OutComms_\" + neighbour\n",
    "    return output_spoken, output_str\n",
    "\n",
    "# Navigation\n",
    "def gen_route():\n",
    "    output_spoken = \" \"\n",
    "    output_str = \"_Route_\"\n",
    "\n",
    "    # Draw route\n",
    "    subaction_type = random.choice(SUB_ACTION_ROUTE)\n",
    "    destination = random.choice(s25_fixes)\n",
    "    \n",
    "    output_str += destination\n",
    "    # Handle each case\n",
    "    if subaction_type == \"On Route\":\n",
    "        output_spoken += random.choice([\"route \", \"route to \", \"route direct \", \"route direct to \"])\n",
    "\n",
    "    elif subaction_type == \"Resume\":\n",
    "        output_spoken += \"resume own navigation \" + random.choice([\"to \", \"direct to \"]) \n",
    "\n",
    "    for letter in destination:\n",
    "        output_spoken += PHONETIC_LETTERS[LETTERS.index(letter)] + \" \"\n",
    "    output_spoken = output_spoken[:-1]\n",
    "\n",
    "    return output_spoken, output_str\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(n_samples):\n",
    "    # output tokens (labels for tokenizer)\n",
    "    speech_spoken = []\n",
    "    # filenames\n",
    "    speech_str = []\n",
    "\n",
    "    # Generate samples\n",
    "    for i in range(n_samples):\n",
    "        sample_spoken = \"\"\n",
    "        sample_str = \"\"\n",
    "\n",
    "        # Generate callsign\n",
    "        callsign_spoken, callsign_str = gen_call_sign()\n",
    "        sample_spoken += callsign_spoken\n",
    "        sample_str += callsign_str\n",
    "\n",
    "        # Generate high level action - [\"Flight Level\", \"Heading\", \"Speed\", \"Incomm\", \"Outcomm\", \"Route\"]\n",
    "        action_type = random.choices(ACTION_TYPE, weights=[5, 5, 5, 1, 3, 5], k=1)[0]\n",
    "\n",
    "        # Handle each type of high level action\n",
    "        gen_fn = None\n",
    "        if action_type == \"Flight Level\":\n",
    "            gen_fn = gen_flight_level\n",
    "        elif action_type == \"Heading\":\n",
    "            gen_fn = gen_heading\n",
    "        elif action_type == \"Speed\":\n",
    "            gen_fn = gen_speed\n",
    "        elif action_type == \"Incomm\":\n",
    "            gen_fn = gen_incomms\n",
    "        elif action_type == \"Outcomm\":\n",
    "            gen_fn = gen_outcomms\n",
    "        elif action_type == \"Route\":\n",
    "            gen_fn = gen_route\n",
    "        \n",
    "        action_spoken, action_str = gen_fn()\n",
    "        sample_spoken += action_spoken\n",
    "        sample_str += action_str\n",
    "\n",
    "\n",
    "        speech_spoken.append(sample_spoken)\n",
    "        speech_str.append(sample_str)\n",
    "    return speech_spoken, speech_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = [x.lower() for x in vocab]\n",
    "# word_tokens = \" \".join(speech_spoken).lower().split(\" \")\n",
    "\n",
    "# counts = np.zeros(len(vocab), dtype=int)\n",
    "# for token in word_tokens:\n",
    "#     try:\n",
    "#         idx = vocab.index(token)\n",
    "#         counts[idx] += 1\n",
    "#     except ValueError:\n",
    "#         pass\n",
    "\n",
    "# token_dist = {\n",
    "#     vocab[i]: counts[i] for i in range(len(vocab))\n",
    "# }\n",
    "# token_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "speech_train, file_train = gen_data(n_samples=500)\n",
    "\n",
    "# Save files\n",
    "for i in range(len(speech_train)):\n",
    "    # Convert str to mp3\n",
    "    myobj = gTTS(text=speech_train[i], lang='en', tld=random.choice(ACCENT), slow=random.choice([True, False]))\n",
    "    myobj.save(\"data_gtts/train/\" + file_train[i] + \".mp3\")\n",
    "\n",
    "# Create metadata\n",
    "filenames_train = [\"data_gtts/train/\" + filename + \".mp3\" for filename in file_train]\n",
    "metadata_train = {\"file_name\": filenames_train, \"transcription\": speech_train}\n",
    "df_train = pd.DataFrame(metadata_train)\n",
    "df_train.to_csv(\"./data_gtts/Train/metadata.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing data\n",
    "speech_test, file_test = gen_data(n_samples=150)\n",
    "\n",
    "# Save files\n",
    "for i in range(len(speech_test)):\n",
    "    # Convert str to mp3\n",
    "    myobj = gTTS(text=speech_test[i], lang='en', tld=random.choice(ACCENT), slow=random.choice([True, False]))\n",
    "    myobj.save(\"data_gtts/test/\" + file_test[i] + \".mp3\")\n",
    "\n",
    "# Create metadata\n",
    "filenames_test = [\"data_gtts/test/\" + filename + \".mp3\" for filename in file_test]\n",
    "metadata_test = {\"file_name\": filenames_test, \"transcription\": speech_test}\n",
    "df_test = pd.DataFrame(metadata_test)\n",
    "df_test.to_csv(\"./data_gtts/test/metadata.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_metadata = pd.concat([df_train, df_test], ignore_index=True)\n",
    "# df_metadata.to_csv(\"./data_gtts/metadata.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-9b41ac5bfd8c70c2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset data_gtts/default to I:/Repos/HFdatasets/data_gtts/default-9b41ac5bfd8c70c2/0.1.0/99611922a2fe30672e990db44b070dc747a16dd2cb691d0d2c33dc670a2e3b68...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b17428d46cc54020a2a6b87f306c3b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe9fa06200345028e7ee06b0bc1c8f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset data_gtts downloaded and prepared to I:/Repos/HFdatasets/data_gtts/default-9b41ac5bfd8c70c2/0.1.0/99611922a2fe30672e990db44b070dc747a16dd2cb691d0d2c33dc670a2e3b68. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4740b127a02e49b78a5cc204333647d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['audio', 'transcription'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['audio', 'transcription'],\n",
       "        num_rows: 5\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"data_gtts\", data_dir=\"I:/Repos/STT_FineTune/nats/data_gtts\")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty folders\n",
    "import os\n",
    "\n",
    "def empty_folders():\n",
    "    dir = './data_gtts/train/'\n",
    "    for f in os.listdir(dir):\n",
    "        os.remove(os.path.join(dir, f))\n",
    "\n",
    "    dir = './data_gtts/test/'\n",
    "    for f in os.listdir(dir):\n",
    "        os.remove(os.path.join(dir, f))\n",
    "\n",
    "# empty_folders()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stt-iPIUnc0I-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0 (tags/v3.9.0:9cf6752, Oct  5 2020, 15:34:40) [MSC v.1927 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7154961865aba29e59721131b5574851dd347dcfb9295715814acc64c5a6540e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
