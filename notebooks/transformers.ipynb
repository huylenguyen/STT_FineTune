{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Introduction**\n",
    "\n",
    "This notebook provides a high-level description of Transformer models and Automatic Speech Recognition problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Transformers**\n",
    "First it is imperative to build a high-level understanding of what a transformer model is. \n",
    "\n",
    "A transformer is a deep neural network which is designed to handle **sequence-to-sequence** data (such as text, audio, or video). Unlike Recurrent Neural Networks (RNNs) - which are also traditionally used for sequential data, Transformer models typically process the entire input all at once instead of (for example) one word at a time. This allows learning to be highly parallelisable, unlike the fully sequential RNNs. The greater parallelisation capabilities allow Transformers to be trained on much larger datasets than was possible previously. \n",
    "\n",
    "One feature of Transformer models is the use of **attention mechanisms**. This is a machine learning technique that allows models to enhance specific parts of the data sequence which are relevant to the learning task, while diminishing the importance of other tasks. This can be thought of as a computational abstraction of cognitive attention mechanisms: when looking at the portrait of a cat, one's attention is naturally drawn to the parts of the image where the cat is present, instead of the background. In a neural network, attention can be generalised as a weight value which describes how relevant the current token in a sequence is to all other tokens. Note that while attention is commonly implemented by Transformers, they are not the only models which implement attention. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pre-Trained Models and Fine-Tuning**\n",
    "With larger parallelised training comes the ability to obtain much larger and robust models. However, training is still an expensive endeavor and not all companies or researchers have access to enough data to sufficiently train a Transformer mode. In the last half decade, much research efforts have shifted from training models from scratch to the new processes of *pre-training* and *fine-tuning* models. \n",
    "\n",
    "Basically, a pre-trained model is typically a large model (upwards of 300 million parameters) which is trained for by organisations with large compute power and data access, typically with some method of self-supervised learning, in order to develop robust internal representations of a particular data mode (e.g. 16khz audio data). The pre-trained model is then published (on platforms such as GitHub or [Hugging Face](https://huggingface.co/)). Other researchers or companies can then use the pre-trained model as a base, and fine-tune it for particular end-point applications, such as Automatic Speech Recognition. The fine-tuning process typically involves adding an additional neural network layer on top of the pre-trained network, and training just this new output layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Automatic Speech Recognition**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic Speech Recognition (ASR) is a sub-domain of Natural Language Processing (NLP) which yet contains a number of further sub-tasks. Typically, these tasks share in common the feature of detecting spoken speech, either from pre-recorded audio files (synchronous speech detection), or live spoken words (streaming/live speech detection). After the speech detection step, the learning task is relatively open, but the most common ones are: Speech-to-text transcription, Speech-to-command detection, etc.\n",
    "\n",
    "So why is this relevant to the topic of Transformers, pre-training and fine-tuning? Currently, the most common approach to designing robust ASR systems involve pre-training a transformer. This transformer will learn to detect the phoneme (the smallest unit of sound) and encode into their internal network representation how their sound patterns are different from each other. With attention, they can even encode how the phonemes are correlated to each other. So by pre-training a Transformer we can transform a sequence of sound to a sequence of internal representations. \n",
    "\n",
    "When we fine-tune the Transformer model, the most common task is to perform phoneme detection. That is, we transform a sequence of internal representations to a sequence of (text-based) phonemes, such as (\"sh\" or \"ph\"). After fine-tuning, we have created a complete model that can translate the \"sh\" sound to the \"sh\" text. A robustly trained model aims to do this for all possible phonemes, which is still a reasonably difficult problem. \n",
    "\n",
    "Finally, we can couple this Transformer model with a trained Language Model (LM). TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('stt-finetune-_3X8IXu5-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "300b9f1d0cbf1292380afbd9c351b06661a32019825097fdc577c2f73fdeaff7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
